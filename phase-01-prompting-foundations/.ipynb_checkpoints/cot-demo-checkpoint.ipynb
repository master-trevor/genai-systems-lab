{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73623cd7",
   "metadata": {},
   "source": [
    "# üß© Chain of Thought (CoT) Demo\n",
    "\n",
    "This notebook demonstrates how prompting GPT-4 with and without Chain of Thought (CoT) affects its reasoning and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2fe9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# Replace with your OpenAI API key\n",
    "openai.api_key = \"sk-...\"\n",
    "\n",
    "def run_gpt(prompt, model=\"gpt-4\"):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.3\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"].strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b605ff9",
   "metadata": {},
   "source": [
    "## üîç Task Example: Logic Puzzle\n",
    "We'll try the same problem twice: once with a plain prompt, once with CoT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef7d1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt without CoT\n",
    "prompt_plain = \"A bat and a ball cost $1.10. The bat costs $1 more than the ball. How much does the ball cost?\"\n",
    "print(\"‚ùå Without CoT:\")\n",
    "print(run_gpt(prompt_plain))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5195fc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt with CoT\n",
    "prompt_cot = \"\"\"A bat and a ball cost $1.10. The bat costs $1 more than the ball. How much does the ball cost?\n",
    "\n",
    "Let's think step by step.\"\"\"\n",
    "print(\"‚úÖ With CoT:\")\n",
    "print(run_gpt(prompt_cot))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5910f8",
   "metadata": {},
   "source": [
    "## üß† Try Your Own!\n",
    "Change the question or add your own prompts below to experiment with Chain of Thought prompting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8b72ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your own CoT prompt here:\n",
    "custom_prompt = \"\"\"Your custom CoT prompt here.\"\"\"\n",
    "print(run_gpt(custom_prompt))"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}